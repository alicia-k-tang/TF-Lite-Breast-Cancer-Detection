{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF Lite Breast Cancer Detection Week 10: Data-Centric AI\n",
    "### Yinda Chen and Alice Tang\n",
    "\n",
    "This week's notebook will focus on refining our pre-processing function to develop a Data-Centric AI approach.\n",
    "\n",
    "We also want to preface that this notebook will unfortunately not run on JupyterHub due to environmental constraints. We had issues with uploading the entire image dataset on JupyterHub, and we did not think training on a subset of data would generate sufficient results. Furthermore, we do plan on taking this model and building a TFLite application, so we wanted to be sure we trained on as much data as possible and create the best model we can.\n",
    "\n",
    "We've used the free GPU P100 on Kaggle to run this notebook. It takes around 23 minutes.\n",
    "\n",
    "#### Let's get started, shall we?\n",
    "\n",
    "To preface, the dataset can be found here: https://www.kaggle.com/datasets/awsaf49/cbis-ddsm-breast-cancer-image-dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20550/4289534611.py:9: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "2024-11-09 19:20:53.229768: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-09 19:20:53.229800: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-09 19:20:53.230292: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-09 19:20:53.233438: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-09 19:20:53.591027: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import PIL\n",
    "import cv2\n",
    "import uuid\n",
    "import shutil\n",
    "import random\n",
    "import glob as gb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm  # Progress bar\n",
    "from scipy.special import gamma\n",
    "\n",
    "from keras.optimizers import *\n",
    "from keras.regularizers import l1_l2\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.layers import Conv2D, MaxPool2D, BatchNormalization\n",
    "\n",
    "from tensorflow.keras.metrics import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created the dir for the benign images and malignant images in the past weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in class 0: 8498\n",
      "Number of images in class 1: 8498\n"
     ]
    }
   ],
   "source": [
    "# Check the number of images in each class folder after merging\n",
    "zero_class_count = len(os.listdir(\"../working/merged_images/0\"))\n",
    "one_class_count  = len(os.listdir(\"../working/merged_images/1\"))\n",
    "\n",
    "print(f\"Number of images in class 0: {zero_class_count}\")\n",
    "print(f\"Number of images in class 1: {one_class_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16996 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-09 19:20:54.707965: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-09 19:20:54.720918: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-09 19:20:54.720945: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-09 19:20:54.722586: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-09 19:20:54.722606: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-09 19:20:54.722616: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-09 19:20:54.817933: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-09 19:20:54.817966: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-09 19:20:54.817970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-11-09 19:20:54.817993: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-09 19:20:54.818004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2024-11-09 19:20:55.052016: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples:      981     batches(13) ==> 12753\n",
      "Validation samples: 261       batches(13) ==> 3393\n",
      "Test samples:       66      batches(13) ==> 858\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../working/merged_images'  # Update with the dataset path\n",
    "\n",
    "# Create a dataset for the entire data to use for split\n",
    "full_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    # image_size=(224, 224),\n",
    "    image_size=(224, 224),\n",
    "    seed=50,\n",
    "    shuffle=True,\n",
    "    batch_size=13\n",
    ")\n",
    "# Calculate the total number of samples\n",
    "total_samples = tf.data.experimental.cardinality(full_dataset).numpy()\n",
    "\n",
    "train_size = int(0.75 * total_samples)                 # 70% for training\n",
    "val_size   = int(0.2 * total_samples)                # 20% for validation\n",
    "test_size = total_samples - train_size - val_size     # 10% for testing\n",
    "\n",
    "# Create train, validation, and test datasets\n",
    "train_dataset       = full_dataset.take(train_size)\n",
    "validation_dataset  = full_dataset.skip(train_size).take(val_size)\n",
    "test_dataset        = full_dataset.skip(train_size + val_size)\n",
    "\n",
    "train_dataset      = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "test_dataset       = test_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# Print the number of samples in each dataset\n",
    "print(f\"Train samples:      {train_size}     batches(13) ==> {train_size*13}\")\n",
    "print(f\"Validation samples: {val_size}       batches(13) ==> {val_size*13}\")\n",
    "print(f\"Test samples:       {test_size}      batches(13) ==> {test_size*13}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetV2B0\n",
    "\n",
    "def model(dropout, trainable_layers):\n",
    "    base_model = EfficientNetV2B0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "    # Freeze all layers initially\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Calculate the index to start unfreezing layers\n",
    "    from_index = int(np.round((len(base_model.layers) - 1) * (1.0 - trainable_layers / 100.0)))\n",
    "\n",
    "    # Unfreeze layers from the calculated index onwards\n",
    "    for layer in base_model.layers[from_index:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Add custom layers on top (Upper-Layers)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = Dropout(dropout)(x)\n",
    "    predictions = Dense(2, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-09 19:21:00.899367: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/block2b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-11-09 19:21:01.543990: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-11-09 19:21:01.615729: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-11-09 19:21:03.182848: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f6c010548a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-11-09 19:21:03.182869: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4060, Compute Capability 8.9\n",
      "2024-11-09 19:21:03.186060: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1731198063.237456   20725 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "981/981 [==============================] - ETA: 0s - loss: 0.7030 - accuracy: 0.6910\n",
      "Epoch 1: val_accuracy improved from -inf to 0.82700, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xpert/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "981/981 [==============================] - 50s 42ms/step - loss: 0.7030 - accuracy: 0.6910 - val_loss: 0.4162 - val_accuracy: 0.8270 - lr: 1.0000e-04\n",
      "Epoch 2/25\n",
      "981/981 [==============================] - ETA: 0s - loss: 0.4553 - accuracy: 0.8000\n",
      "Epoch 2: val_accuracy improved from 0.82700 to 0.85912, saving model to best_model.h5\n",
      "981/981 [==============================] - 40s 41ms/step - loss: 0.4553 - accuracy: 0.8000 - val_loss: 0.3401 - val_accuracy: 0.8591 - lr: 1.0000e-04\n",
      "Epoch 3/25\n",
      "981/981 [==============================] - ETA: 0s - loss: 0.3482 - accuracy: 0.8542\n",
      "Epoch 3: val_accuracy improved from 0.85912 to 0.90333, saving model to best_model.h5\n",
      "981/981 [==============================] - 38s 39ms/step - loss: 0.3482 - accuracy: 0.8542 - val_loss: 0.2381 - val_accuracy: 0.9033 - lr: 1.0000e-04\n",
      "Epoch 4/25\n",
      "981/981 [==============================] - ETA: 0s - loss: 0.2805 - accuracy: 0.8852\n",
      "Epoch 4: val_accuracy improved from 0.90333 to 0.92249, saving model to best_model.h5\n",
      "981/981 [==============================] - 42s 43ms/step - loss: 0.2805 - accuracy: 0.8852 - val_loss: 0.2038 - val_accuracy: 0.9225 - lr: 1.0000e-04\n",
      "Epoch 5/25\n",
      "980/981 [============================>.] - ETA: 0s - loss: 0.2337 - accuracy: 0.9059\n",
      "Epoch 5: val_accuracy did not improve from 0.92249\n",
      "981/981 [==============================] - 42s 42ms/step - loss: 0.2336 - accuracy: 0.9059 - val_loss: 0.2243 - val_accuracy: 0.9169 - lr: 1.0000e-04\n",
      "Epoch 6/25\n",
      "981/981 [==============================] - ETA: 0s - loss: 0.2148 - accuracy: 0.9133\n",
      "Epoch 6: val_accuracy improved from 0.92249 to 0.93870, saving model to best_model.h5\n",
      "981/981 [==============================] - 40s 41ms/step - loss: 0.2148 - accuracy: 0.9133 - val_loss: 0.1856 - val_accuracy: 0.9387 - lr: 1.0000e-04\n",
      "Epoch 7/25\n",
      "981/981 [==============================] - ETA: 0s - loss: 0.2047 - accuracy: 0.9187\n",
      "Epoch 7: val_accuracy improved from 0.93870 to 0.95167, saving model to best_model.h5\n",
      "981/981 [==============================] - 41s 42ms/step - loss: 0.2047 - accuracy: 0.9187 - val_loss: 0.1575 - val_accuracy: 0.9517 - lr: 1.0000e-04\n",
      "Epoch 8/25\n",
      "981/981 [==============================] - ETA: 0s - loss: 0.1755 - accuracy: 0.9301\n",
      "Epoch 8: val_accuracy did not improve from 0.95167\n",
      "981/981 [==============================] - 41s 41ms/step - loss: 0.1755 - accuracy: 0.9301 - val_loss: 0.1655 - val_accuracy: 0.9487 - lr: 1.0000e-04\n",
      "Epoch 9/25\n",
      "981/981 [==============================] - ETA: 0s - loss: 0.1684 - accuracy: 0.9363\n",
      "Epoch 9: val_accuracy improved from 0.95167 to 0.95520, saving model to best_model.h5\n",
      "981/981 [==============================] - 38s 38ms/step - loss: 0.1684 - accuracy: 0.9363 - val_loss: 0.1473 - val_accuracy: 0.9552 - lr: 1.0000e-04\n",
      "Epoch 10/25\n",
      "981/981 [==============================] - ETA: 0s - loss: 0.1484 - accuracy: 0.9425\n",
      "Epoch 10: val_accuracy did not improve from 0.95520\n",
      "981/981 [==============================] - 39s 40ms/step - loss: 0.1484 - accuracy: 0.9425 - val_loss: 0.1749 - val_accuracy: 0.9484 - lr: 1.0000e-04\n",
      "Epoch 11/25\n",
      "980/981 [============================>.] - ETA: 0s - loss: 0.1420 - accuracy: 0.9457\n",
      "Epoch 11: val_accuracy improved from 0.95520 to 0.96434, saving model to best_model.h5\n",
      "981/981 [==============================] - 40s 41ms/step - loss: 0.1420 - accuracy: 0.9457 - val_loss: 0.1297 - val_accuracy: 0.9643 - lr: 1.0000e-04\n",
      "Epoch 12/25\n",
      "981/981 [==============================] - ETA: 0s - loss: 0.1367 - accuracy: 0.9464\n",
      "Epoch 12: val_accuracy did not improve from 0.96434\n",
      "981/981 [==============================] - 39s 40ms/step - loss: 0.1367 - accuracy: 0.9464 - val_loss: 0.1415 - val_accuracy: 0.9584 - lr: 1.0000e-04\n",
      "Epoch 13/25\n",
      "981/981 [==============================] - ETA: 0s - loss: 0.1226 - accuracy: 0.9544\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 13: val_accuracy did not improve from 0.96434\n",
      "981/981 [==============================] - 41s 42ms/step - loss: 0.1226 - accuracy: 0.9544 - val_loss: 0.1443 - val_accuracy: 0.9558 - lr: 1.0000e-04\n",
      "Epoch 14/25\n",
      "981/981 [==============================] - ETA: 0s - loss: 0.0978 - accuracy: 0.9637\n",
      "Epoch 14: val_accuracy did not improve from 0.96434\n",
      "981/981 [==============================] - 39s 40ms/step - loss: 0.0978 - accuracy: 0.9637 - val_loss: 0.1148 - val_accuracy: 0.9620 - lr: 5.0000e-05\n",
      "Epoch 15/25\n",
      "981/981 [==============================] - ETA: 0s - loss: 0.0963 - accuracy: 0.9623\n",
      "Epoch 15: val_accuracy improved from 0.96434 to 0.96758, saving model to best_model.h5\n",
      "981/981 [==============================] - 40s 40ms/step - loss: 0.0963 - accuracy: 0.9623 - val_loss: 0.1236 - val_accuracy: 0.9676 - lr: 5.0000e-05\n",
      "Epoch 16/25\n",
      "981/981 [==============================] - ETA: 0s - loss: 0.0798 - accuracy: 0.9717\n",
      "Epoch 16: val_accuracy improved from 0.96758 to 0.97200, saving model to best_model.h5\n",
      "981/981 [==============================] - 41s 42ms/step - loss: 0.0798 - accuracy: 0.9717 - val_loss: 0.1012 - val_accuracy: 0.9720 - lr: 5.0000e-05\n",
      "Epoch 17/25\n",
      "981/981 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9722\n",
      "Epoch 17: val_accuracy did not improve from 0.97200\n",
      "981/981 [==============================] - 39s 40ms/step - loss: 0.0763 - accuracy: 0.9722 - val_loss: 0.1150 - val_accuracy: 0.9714 - lr: 5.0000e-05\n",
      "Epoch 18/25\n",
      "981/981 [==============================] - ETA: 0s - loss: 0.0774 - accuracy: 0.9711\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 18: val_accuracy did not improve from 0.97200\n",
      "981/981 [==============================] - 38s 38ms/step - loss: 0.0774 - accuracy: 0.9711 - val_loss: 0.1130 - val_accuracy: 0.9673 - lr: 5.0000e-05\n",
      "Epoch 19/25\n",
      "980/981 [============================>.] - ETA: 0s - loss: 0.0724 - accuracy: 0.9725\n",
      "Epoch 19: val_accuracy improved from 0.97200 to 0.97318, saving model to best_model.h5\n",
      "981/981 [==============================] - 38s 39ms/step - loss: 0.0723 - accuracy: 0.9726 - val_loss: 0.1055 - val_accuracy: 0.9732 - lr: 2.5000e-05\n",
      "Epoch 20/25\n",
      "981/981 [==============================] - ETA: 0s - loss: 0.0625 - accuracy: 0.9759\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 20: val_accuracy did not improve from 0.97318\n",
      "981/981 [==============================] - 40s 41ms/step - loss: 0.0625 - accuracy: 0.9759 - val_loss: 0.1032 - val_accuracy: 0.9729 - lr: 2.5000e-05\n",
      "Epoch 20: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, \n",
    "                              min_lr=5e-6, verbose=1)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4, \n",
    "                               restore_best_weights=False, verbose=1)\n",
    "\n",
    "# ModelCheckpoint callback to save the best model based on validation accuracy\n",
    "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', \n",
    "                             mode='max', save_best_only=True, verbose=1)\n",
    "\n",
    "model = model(0.1, 20)\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "            train_dataset,\n",
    "            validation_data=validation_dataset,\n",
    "            batch_size=13,\n",
    "            epochs=25,\n",
    "            callbacks=[reduce_lr, early_stopping, checkpoint],\n",
    "            verbose=1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16996 files belonging to 2 classes.\n",
      "Train samples:      981     batches(13) ==> 12753\n",
      "Validation samples: 261       batches(13) ==> 3393\n",
      "Test samples:       66      batches(13) ==> 858\n"
     ]
    }
   ],
   "source": [
    "full_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    # image_size=(224, 224),\n",
    "    image_size=(224, 224),\n",
    "    seed=50,\n",
    "    shuffle=False,\n",
    "    batch_size=13\n",
    ")\n",
    "# Calculate the total number of samples\n",
    "total_samples = tf.data.experimental.cardinality(full_dataset).numpy()\n",
    "\n",
    "train_size = int(0.75 * total_samples)                 # 70% for training\n",
    "val_size   = int(0.2 * total_samples)                # 20% for validation\n",
    "test_size = total_samples - train_size - val_size     # 10% for testing\n",
    "\n",
    "# Create train, validation, and test datasets\n",
    "train_dataset       = full_dataset.take(train_size)\n",
    "validation_dataset  = full_dataset.skip(train_size).take(val_size)\n",
    "test_dataset        = full_dataset.skip(train_size + val_size)\n",
    "\n",
    "train_dataset      = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "test_dataset       = test_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# Print the number of samples in each dataset\n",
    "print(f\"Train samples:      {train_size}     batches(13) ==> {train_size*13}\")\n",
    "print(f\"Validation samples: {val_size}       batches(13) ==> {val_size*13}\")\n",
    "print(f\"Test samples:       {test_size}      batches(13) ==> {test_size*13}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 2s 23ms/step - loss: 0.0631 - accuracy: 0.9847\n",
      "Test Accuracy: 0.9847058653831482\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"best_model.h5\")\n",
    "\n",
    "\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset, verbose=1)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 2s 21ms/step\n",
      "Precision: 1.0\n",
      "Recall: 0.9847058823529412\n",
      "F1 Score: 0.992294013040901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xpert/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Get the prediciton\n",
    "y_pred = model.predict(test_dataset)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Get the true labels\n",
    "y_true = np.concatenate([y for x, y in test_dataset], axis=0)\n",
    "y_true_classes = np.argmax(y_true, axis=1)\n",
    "\n",
    "# Calculate Precision, Recall and F1 Score\n",
    "precision = precision_score(y_true_classes, y_pred_classes, average='weighted')\n",
    "recall = recall_score(y_true_classes, y_pred_classes, average='weighted')\n",
    "f1 = f1_score(y_true_classes, y_pred_classes, average='weighted')\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This marks the start of Week 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Improvements and Enhancements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MammogramPreProcessor:\n",
    "    def __init__(self, target_size=(224, 224)):\n",
    "        self.target_size = target_size\n",
    "\n",
    "    # Function 1\n",
    "    @tf.function\n",
    "    def remove_background_tf(self, image):\n",
    "        \"\"\"\n",
    "        TensorFlow implementation for background removal.\n",
    "        \"\"\"\n",
    "        # Convert to grayscale if it's a 3-channel image\n",
    "        if tf.shape(image)[-1] == 3:\n",
    "            image = tf.image.rgb_to_grayscale(image)\n",
    "        \n",
    "        # Create a binary mask\n",
    "        threshold = tf.cast(5, dtype=tf.float32)\n",
    "        binary_mask = tf.cast(image > threshold, tf.float32)\n",
    "        \n",
    "        # Apply the mask\n",
    "        return image * binary_mask\n",
    "\n",
    "    # Function 2\n",
    "    @tf.function\n",
    "    def apply_clahe_tf(self, image):\n",
    "        \"\"\"\n",
    "        TensorFlow implementation for CLAHE enhancement.\n",
    "        \"\"\"\n",
    "        # Normalize to the range 0-255\n",
    "        image = tf.cast(image, tf.float32)\n",
    "        image = (image - tf.reduce_min(image)) / (tf.reduce_max(image) - tf.reduce_min(image)) * 255\n",
    "        return image\n",
    "\n",
    "    # Function 3\n",
    "    @tf.function\n",
    "    def normalize_tf(self, image):\n",
    "        \"\"\"\n",
    "        Normalize the image.\n",
    "        \"\"\"\n",
    "        image = tf.cast(image, tf.float32)\n",
    "        mean = tf.reduce_mean(image)\n",
    "        std = tf.math.reduce_std(image)\n",
    "        return (image - mean) / (std + 1e-7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_preprocessing_pipeline(target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Create a complete preprocessing pipeline.\n",
    "    \"\"\"\n",
    "    processor = MammogramPreProcessor(target_size)\n",
    "    \n",
    "    def preprocess_function(images, labels):\n",
    "        # Process each image in the batch\n",
    "        def process_single_image(image):\n",
    "            # Remove background\n",
    "            image = processor.remove_background_tf(image)\n",
    "            \n",
    "            # Apply CLAHE enhancement\n",
    "            image = processor.apply_clahe_tf(image)\n",
    "            \n",
    "            # Normalize the image\n",
    "            image = processor.normalize_tf(image)\n",
    "            \n",
    "            # Ensure correct size\n",
    "            image = tf.image.resize(image, target_size)\n",
    "            \n",
    "            # Ensure the correct number of channels (if 3 channels are needed)\n",
    "            image = tf.tile(image, [1, 1, 3])\n",
    "            \n",
    "            return image\n",
    "        \n",
    "        # Process the entire batch\n",
    "        processed_images = tf.map_fn(process_single_image, images)\n",
    "        return processed_images, labels\n",
    "\n",
    "    return preprocess_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(full_dataset, batch_size=13):\n",
    "    \"\"\"\n",
    "    prepare for the dataset and preprocessing.\n",
    "    \"\"\"\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "    \n",
    "    # create the preprocess pipeline\n",
    "    preprocess_fn = create_preprocessing_pipeline(target_size=(224, 224))\n",
    "    \n",
    "    # apply the preprocess\n",
    "    processed_dataset = full_dataset.map(preprocess_fn, num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    # improve the performance\n",
    "    processed_dataset = processed_dataset.cache()\n",
    "    processed_dataset = processed_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    return processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16996 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "full_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    # image_size=(224, 224),\n",
    "    image_size=(224, 224),\n",
    "    seed=50,\n",
    "    shuffle=True,\n",
    "    batch_size=13\n",
    ")\n",
    "\n",
    "processed_dataset = prepare_dataset(full_dataset)\n",
    "\n",
    "total_samples = tf.data.experimental.cardinality(processed_dataset).numpy()\n",
    "\n",
    "train_size = int(0.75 * total_samples)                 # 70% for training\n",
    "val_size   = int(0.2 * total_samples)                # 20% for validation\n",
    "test_size = total_samples - train_size - val_size     # 10% for testing\n",
    "\n",
    "# Create train, validation, and test datasets\n",
    "train_dataset       = full_dataset.take(train_size)\n",
    "validation_dataset  = full_dataset.skip(train_size).take(val_size)\n",
    "test_dataset        = full_dataset.skip(train_size + val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-09 19:44:16.431008: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_1/block2b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "981/981 [==============================] - ETA: 0s - loss: 0.6918 - accuracy: 0.6878\n",
      "Epoch 1: val_accuracy improved from -inf to 0.82582, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xpert/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "981/981 [==============================] - 49s 43ms/step - loss: 0.6918 - accuracy: 0.6878 - val_loss: 0.4172 - val_accuracy: 0.8258 - lr: 1.0000e-04\n",
      "Epoch 2/25\n",
      "981/981 [==============================] - ETA: 0s - loss: 0.4488 - accuracy: 0.8035\n",
      "Epoch 2: val_accuracy improved from 0.82582 to 0.86325, saving model to best_model.h5\n",
      "981/981 [==============================] - 41s 42ms/step - loss: 0.4488 - accuracy: 0.8035 - val_loss: 0.3231 - val_accuracy: 0.8632 - lr: 1.0000e-04\n",
      "Epoch 3/25\n",
      "980/981 [============================>.] - ETA: 0s - loss: 0.3325 - accuracy: 0.8589\n",
      "Epoch 3: val_accuracy improved from 0.86325 to 0.91306, saving model to best_model.h5\n",
      "981/981 [==============================] - 41s 42ms/step - loss: 0.3324 - accuracy: 0.8590 - val_loss: 0.2273 - val_accuracy: 0.9131 - lr: 1.0000e-04\n",
      "Epoch 4/25\n",
      "981/981 [==============================] - ETA: 0s - loss: 0.2770 - accuracy: 0.8825\n",
      "Epoch 4: val_accuracy improved from 0.91306 to 0.92986, saving model to best_model.h5\n",
      "981/981 [==============================] - 41s 41ms/step - loss: 0.2770 - accuracy: 0.8825 - val_loss: 0.1805 - val_accuracy: 0.9299 - lr: 1.0000e-04\n",
      "Epoch 5/25\n",
      "980/981 [============================>.] - ETA: 0s - loss: 0.2366 - accuracy: 0.9038\n",
      "Epoch 5: val_accuracy did not improve from 0.92986\n",
      "981/981 [==============================] - 41s 42ms/step - loss: 0.2367 - accuracy: 0.9039 - val_loss: 0.2057 - val_accuracy: 0.9240 - lr: 1.0000e-04\n",
      "Epoch 6/25\n",
      "981/981 [==============================] - ETA: 0s - loss: 0.2071 - accuracy: 0.9185\n",
      "Epoch 6: val_accuracy improved from 0.92986 to 0.94931, saving model to best_model.h5\n",
      "981/981 [==============================] - 40s 41ms/step - loss: 0.2071 - accuracy: 0.9185 - val_loss: 0.1448 - val_accuracy: 0.9493 - lr: 1.0000e-04\n",
      "Epoch 7/25\n",
      "981/981 [==============================] - ETA: 0s - loss: 0.1929 - accuracy: 0.9246\n",
      "Epoch 7: val_accuracy did not improve from 0.94931\n",
      "981/981 [==============================] - 40s 41ms/step - loss: 0.1929 - accuracy: 0.9246 - val_loss: 0.1536 - val_accuracy: 0.9475 - lr: 1.0000e-04\n",
      "Epoch 8/25\n",
      "981/981 [==============================] - ETA: 0s - loss: 0.1712 - accuracy: 0.9337\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.94931\n",
      "981/981 [==============================] - 41s 42ms/step - loss: 0.1712 - accuracy: 0.9337 - val_loss: 0.1610 - val_accuracy: 0.9475 - lr: 1.0000e-04\n",
      "Epoch 9/25\n",
      "980/981 [============================>.] - ETA: 0s - loss: 0.1357 - accuracy: 0.9502\n",
      "Epoch 9: val_accuracy improved from 0.94931 to 0.96522, saving model to best_model.h5\n",
      "981/981 [==============================] - 40s 41ms/step - loss: 0.1356 - accuracy: 0.9502 - val_loss: 0.1053 - val_accuracy: 0.9652 - lr: 5.0000e-05\n",
      "Epoch 10/25\n",
      "981/981 [==============================] - ETA: 0s - loss: 0.1190 - accuracy: 0.9546\n",
      "Epoch 10: val_accuracy did not improve from 0.96522\n",
      "981/981 [==============================] - 40s 41ms/step - loss: 0.1190 - accuracy: 0.9546 - val_loss: 0.1104 - val_accuracy: 0.9637 - lr: 5.0000e-05\n",
      "Epoch 11/25\n",
      "981/981 [==============================] - ETA: 0s - loss: 0.1147 - accuracy: 0.9571\n",
      "Epoch 11: val_accuracy improved from 0.96522 to 0.96729, saving model to best_model.h5\n",
      "981/981 [==============================] - 40s 41ms/step - loss: 0.1147 - accuracy: 0.9571 - val_loss: 0.1027 - val_accuracy: 0.9673 - lr: 5.0000e-05\n",
      "Epoch 12/25\n",
      "981/981 [==============================] - ETA: 0s - loss: 0.1115 - accuracy: 0.9581\n",
      "Epoch 12: val_accuracy did not improve from 0.96729\n",
      "981/981 [==============================] - 40s 40ms/step - loss: 0.1115 - accuracy: 0.9581 - val_loss: 0.1089 - val_accuracy: 0.9658 - lr: 5.0000e-05\n",
      "Epoch 13/25\n",
      "981/981 [==============================] - ETA: 0s - loss: 0.0998 - accuracy: 0.9634\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 13: val_accuracy did not improve from 0.96729\n",
      "981/981 [==============================] - 40s 40ms/step - loss: 0.0998 - accuracy: 0.9634 - val_loss: 0.1210 - val_accuracy: 0.9623 - lr: 5.0000e-05\n",
      "Epoch 14/25\n",
      "981/981 [==============================] - ETA: 0s - loss: 0.0931 - accuracy: 0.9658\n",
      "Epoch 14: val_accuracy improved from 0.96729 to 0.97023, saving model to best_model.h5\n",
      "981/981 [==============================] - 40s 41ms/step - loss: 0.0931 - accuracy: 0.9658 - val_loss: 0.1012 - val_accuracy: 0.9702 - lr: 2.5000e-05\n",
      "Epoch 15/25\n",
      "981/981 [==============================] - ETA: 0s - loss: 0.0874 - accuracy: 0.9675\n",
      "Epoch 15: val_accuracy did not improve from 0.97023\n",
      "981/981 [==============================] - 40s 40ms/step - loss: 0.0874 - accuracy: 0.9675 - val_loss: 0.0974 - val_accuracy: 0.9679 - lr: 2.5000e-05\n",
      "Epoch 16/25\n",
      "981/981 [==============================] - ETA: 0s - loss: 0.0761 - accuracy: 0.9726\n",
      "Epoch 16: val_accuracy improved from 0.97023 to 0.97200, saving model to best_model.h5\n",
      "981/981 [==============================] - 40s 41ms/step - loss: 0.0761 - accuracy: 0.9726 - val_loss: 0.0891 - val_accuracy: 0.9720 - lr: 2.5000e-05\n",
      "Epoch 17/25\n",
      "981/981 [==============================] - ETA: 0s - loss: 0.0741 - accuracy: 0.9727\n",
      "Epoch 17: val_accuracy improved from 0.97200 to 0.97347, saving model to best_model.h5\n",
      "981/981 [==============================] - 40s 41ms/step - loss: 0.0741 - accuracy: 0.9727 - val_loss: 0.0935 - val_accuracy: 0.9735 - lr: 2.5000e-05\n",
      "Epoch 18/25\n",
      "981/981 [==============================] - ETA: 0s - loss: 0.0696 - accuracy: 0.9756\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 18: val_accuracy did not improve from 0.97347\n",
      "981/981 [==============================] - 40s 41ms/step - loss: 0.0696 - accuracy: 0.9756 - val_loss: 0.0992 - val_accuracy: 0.9735 - lr: 2.5000e-05\n",
      "Epoch 19/25\n",
      "981/981 [==============================] - ETA: 0s - loss: 0.0694 - accuracy: 0.9755\n",
      "Epoch 19: val_accuracy improved from 0.97347 to 0.97554, saving model to best_model.h5\n",
      "981/981 [==============================] - 40s 41ms/step - loss: 0.0694 - accuracy: 0.9755 - val_loss: 0.0936 - val_accuracy: 0.9755 - lr: 1.2500e-05\n",
      "Epoch 20/25\n",
      "981/981 [==============================] - ETA: 0s - loss: 0.0650 - accuracy: 0.9762\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 20: val_accuracy did not improve from 0.97554\n",
      "981/981 [==============================] - 40s 40ms/step - loss: 0.0650 - accuracy: 0.9762 - val_loss: 0.0986 - val_accuracy: 0.9735 - lr: 1.2500e-05\n",
      "Epoch 20: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, \n",
    "                              min_lr=5e-6, verbose=1)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4, \n",
    "                               restore_best_weights=False, verbose=1)\n",
    "\n",
    "# ModelCheckpoint callback to save the best model based on validation accuracy\n",
    "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', \n",
    "                             mode='max', save_best_only=True, verbose=1)\n",
    "\n",
    "model = model(0.1, 20)\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "            train_dataset,\n",
    "            validation_data=validation_dataset,\n",
    "            batch_size=13,\n",
    "            epochs=25,\n",
    "            callbacks=[reduce_lr, early_stopping, checkpoint],\n",
    "            verbose=1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16996 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "full_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    # image_size=(224, 224),\n",
    "    image_size=(224, 224),\n",
    "    seed=50,\n",
    "    shuffle=False,\n",
    "    batch_size=13\n",
    ")\n",
    "\n",
    "processed_dataset = prepare_dataset(full_dataset)\n",
    "\n",
    "total_samples = tf.data.experimental.cardinality(processed_dataset).numpy()\n",
    "\n",
    "train_size = int(0.75 * total_samples)                 # 70% for training\n",
    "val_size   = int(0.2 * total_samples)                # 20% for validation\n",
    "test_size = total_samples - train_size - val_size     # 10% for testing\n",
    "\n",
    "# Create train, validation, and test datasets\n",
    "train_dataset       = full_dataset.take(train_size)\n",
    "validation_dataset  = full_dataset.skip(train_size).take(val_size)\n",
    "test_dataset        = full_dataset.skip(train_size + val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 2s 22ms/step - loss: 0.0490 - accuracy: 0.9859\n",
      "Test Accuracy: 0.9858823418617249\n",
      "66/66 [==============================] - 2s 16ms/step\n",
      "Precision: 1.0\n",
      "Recall: 0.9858823529411764\n",
      "F1 Score: 0.9928909952606635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xpert/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"best_model.h5\")\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset, verbose=1)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Get the prediciton\n",
    "y_pred = model.predict(test_dataset)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Get the true labels\n",
    "y_true = np.concatenate([y for x, y in test_dataset], axis=0)\n",
    "y_true_classes = np.argmax(y_true, axis=1)\n",
    "\n",
    "# Calculate Precision, Recall and F1 Score\n",
    "precision = precision_score(y_true_classes, y_pred_classes, average='weighted')\n",
    "recall = recall_score(y_true_classes, y_pred_classes, average='weighted')\n",
    "f1 = f1_score(y_true_classes, y_pred_classes, average='weighted')\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
